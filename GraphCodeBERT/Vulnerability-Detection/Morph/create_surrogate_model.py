import csv

from mo_distill_utils import distill, hyperparams_convert
from flops import TransformerHparams
from many_objective import convert_chromosomes, ModelCompressionProblem, LatinHypercubeSampler


if __name__ == "__main__":
    # Define the lower and upper bounds
    lb = [1, 1000, 1, 16, 1, 0.2, 32, 1, 0.2, 256, 1, 1, 1]
    ub = [4, 46000, 12, 256, 4, 0.5, 3072, 12, 0.5, 512, 3, 3, 3]

    # Number of points to generate
    n_points = 50

    problem = ModelCompressionProblem(lb, ub, None)
    sampler = LatinHypercubeSampler()

    surrogate_data = convert_chromosomes(sampler._do(problem, n_points))

    print("Create surrogate models")

    fieldnames = ["Tokenizer", "Vocab Size", "Num Hidden Layers", "Hidden Size", "Hidden Act", "Hidden Dropout Prob",
                  "Intermediate Size", "Num Attention Heads", "Attention Probs Dropout Prob", "Max Sequence Length",
                  "Position Embedding Type", "Learning Rate", "Batch Size", "Accuracy",
                  "Prediction Flips"]

    results_file = "surrogate_data_metamorphic.csv"

    # Write the header only if the file is empty
    with open(results_file, 'a', newline='') as file:
        writer = csv.DictWriter(file, fieldnames=fieldnames)
        if file.tell() == 0:
            writer.writeheader()

    for i in range(0, len(surrogate_data)):
        data = surrogate_data[i]
        # trains the models
        accs, prediction_flips = distill([data], eval=False, surrogate=True, robust=True,model_name=f'model-{i}.bin',seed=42)
        model = TransformerHparams(data[3], data[2], data[9],
                                   data[1], data[6], data[7])

        row_data = hyperparams_convert(data)
        row_data += [accs[0], prediction_flips[0]]

        # Create a dictionary from row_data
        row_dict = dict(zip(fieldnames, row_data))

        with open(results_file, 'a', newline='') as file:
            writer = csv.DictWriter(file, fieldnames=fieldnames)
            writer.writerow(row_dict)