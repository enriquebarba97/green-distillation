Tokenizer,Vocab Size,Num Hidden Layers,Hidden Size,Hidden Act,Hidden Dropout Prob,Intermediate Size,Num Attention Heads,Attention Probs Dropout Prob,Max Sequence Length,Position Embedding Type,Learning Rate,Batch Size,Size,Accuracy,FLOPS,Flips
3,34850,1,18,1,0.2,2545,3,0.2,263,3,3,2,2.9722350206213575,0.5988286969253295,1068.0,320
3,1319,7,20,1,0.3,2433,4,0.3,358,2,3,3,2.8664296640990816,0.5743045387994143,22793.0,186
4,4073,7,15,2,0.4,2926,5,0.4,475,1,3,3,2.9037538330438224,0.5406295754026355,29635.0,0
3,3550,9,16,2,0.3,2567,4,0.3,269,2,3,1,3.2205303465979824,0.5640556368960469,24414.0,141
3,4977,6,18,1,0.2,2820,6,0.2,503,3,3,2,3.04093243018864,0.5933382137628112,58960.0,270
2,36012,1,16,1,0.2,2667,2,0.2,257,2,3,1,2.6937657055002773,0.5874816983894583,2056.0,316
4,4775,8,16,4,0.3,2707,4,0.3,504,2,3,2,3.0980368576952313,0.544289897510981,85380.0,5
3,3693,7,18,1,0.3,2464,3,0.3,369,3,2,3,3.03476664600075,0.5911420204978038,26268.0,293
4,3862,7,18,2,0.4,2703,6,0.4,509,2,3,2,3.1854046099325126,0.5592972181551976,52505.0,76
4,1806,5,22,1,0.5,2955,1,0.5,466,1,2,3,3.069280307645329,0.5761346998535871,26075.0,320
4,3774,8,16,1,0.2,2656,4,0.2,502,2,3,1,3.0521703994107545,0.5644216691068814,70193.0,179
3,4552,7,15,3,0.4,3031,5,0.4,488,2,3,3,2.9845490096106806,0.5406295754026355,33468.0,0
3,3943,8,14,1,0.4,2686,7,0.4,505,3,3,1,2.74757127330151,0.5406295754026355,84659.0,0
4,1060,2,175,1,0.3,264,1,0.3,496,1,3,3,2.964988162362038,0.5691800878477306,0.0,269
3,3984,7,18,3,0.3,2946,6,0.3,488,3,3,2,3.21372305313321,0.5424597364568082,37126.0,7
3,3236,8,15,1,0.4,2528,5,0.4,272,3,3,3,2.785227149998709,0.5406295754026355,21300.0,0
3,1001,2,165,2,0.4,680,3,0.4,500,1,3,3,3.9855671451477503,0.5878477306002928,2273.0,292
3,4669,7,16,1,0.3,3015,4,0.3,302,3,3,2,3.022032173192652,0.5406295754026355,15858.0,0
4,4424,7,15,3,0.3,2873,3,0.3,511,2,2,3,2.9999375461221685,0.5519765739385066,66388.0,152
3,5595,7,18,1,0.2,2474,6,0.2,500,2,3,2,3.094567064896785,0.5962664714494875,50846.0,311
